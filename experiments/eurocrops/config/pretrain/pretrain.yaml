name: "${base_name} - pretrain"
key_metric: "Acc"
tuning_params:
  floats:
    lr:
      log: True
      low: 1.0e-4
      high: 1.0e-2
  ints: {}
  categoricals:
    epochs: [100]
tuning_workers: 1
tuning_trials: 8 # per worker
tuning_sampler: "tpe" # "grid" or "random" or "tpe"
tuning_pruning_percentile: 75 # top Xth percentile of runs kept, e.g., set 50 for median rule, or None for no pruning
tuning_pruning_warmup_steps: 100 # counts in batches not epochs
validate_every: 1
log_artifact_metrics_on_validation: False

train_config:
  batch_size: 128
  epochs: 150
  lr: 1e-5
  weight_decay: 0.0
  cosine_annealing: 0
  stop_early: True
  patience: 15
